import express from 'express'\nimport { body, validationResult } from 'express-validator'\nimport OpenAI from 'openai'\nimport { Replicate } from 'replicate'\nimport { PrismaClient } from '@prisma/client'\nimport { logger } from '../utils/logger'\nimport { rateLimitByUser } from '../middleware/rateLimiter'\n\nconst router = express.Router()\nconst prisma = new PrismaClient()\n\n// Initialize AI services\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n})\n\nconst replicate = new Replicate({\n  auth: process.env.REPLICATE_API_TOKEN\n})\n\n// Text Generation Routes\nrouter.post('/text/generate',\n  rateLimitByUser(10, 60), // 10 requests per minute per user\n  [\n    body('prompt').isString().isLength({ min: 1, max: 2000 }),\n    body('model').optional().isIn(['gpt-4', 'gpt-3.5-turbo']),\n    body('maxTokens').optional().isInt({ min: 1, max: 4000 }),\n    body('temperature').optional().isFloat({ min: 0, max: 2 })\n  ],\n  async (req, res) => {\n    try {\n      const errors = validationResult(req)\n      if (!errors.isEmpty()) {\n        return res.status(400).json({ errors: errors.array() })\n      }\n\n      const { prompt, model = 'gpt-3.5-turbo', maxTokens = 1000, temperature = 0.7 } = req.body\n      const userId = req.user.id\n\n      // Log the request\n      logger.info(`Text generation request from user ${userId}`, {\n        model,\n        promptLength: prompt.length,\n        maxTokens,\n        temperature\n      })\n\n      const completion = await openai.chat.completions.create({\n        model,\n        messages: [{ role: 'user', content: prompt }],\n        max_tokens: maxTokens,\n        temperature,\n        user: userId\n      })\n\n      const generatedText = completion.choices[0]?.message?.content || ''\n      const tokensUsed = completion.usage?.total_tokens || 0\n\n      // Save to database\n      const generation = await prisma.textGeneration.create({\n        data: {\n          userId,\n          prompt,\n          generatedText,\n          model,\n          tokensUsed,\n          parameters: {\n            maxTokens,\n            temperature\n          }\n        }\n      })\n\n      res.json({\n        id: generation.id,\n        text: generatedText,\n        tokensUsed,\n        model,\n        createdAt: generation.createdAt\n      })\n\n    } catch (error) {\n      logger.error('Text generation error:', error)\n      res.status(500).json({\n        error: 'Text generation failed',\n        message: error instanceof Error ? error.message : 'Unknown error'\n      })\n    }\n  }\n)\n\n// Text Summarization\nrouter.post('/text/summarize',\n  rateLimitByUser(5, 60),\n  [\n    body('text').isString().isLength({ min: 100, max: 10000 }),\n    body('length').optional().isIn(['short', 'medium', 'long'])\n  ],\n  async (req, res) => {\n    try {\n      const errors = validationResult(req)\n      if (!errors.isEmpty()) {\n        return res.status(400).json({ errors: errors.array() })\n      }\n\n      const { text, length = 'medium' } = req.body\n      const userId = req.user.id\n\n      const lengthInstructions = {\n        short: 'in 1-2 sentences',\n        medium: 'in 3-5 sentences',\n        long: 'in 1-2 paragraphs'\n      }\n\n      const prompt = `Please summarize the following text ${lengthInstructions[length]}:\\n\\n${text}`\n\n      const completion = await openai.chat.completions.create({\n        model: 'gpt-3.5-turbo',\n        messages: [{ role: 'user', content: prompt }],\n        max_tokens: length === 'short' ? 100 : length === 'medium' ? 200 : 400,\n        temperature: 0.3,\n        user: userId\n      })\n\n      const summary = completion.choices[0]?.message?.content || ''\n      const tokensUsed = completion.usage?.total_tokens || 0\n\n      // Save to database\n      await prisma.textGeneration.create({\n        data: {\n          userId,\n          prompt,\n          generatedText: summary,\n          model: 'gpt-3.5-turbo',\n          tokensUsed,\n          type: 'summarization'\n        }\n      })\n\n      res.json({\n        summary,\n        originalLength: text.length,\n        summaryLength: summary.length,\n        tokensUsed\n      })\n\n    } catch (error) {\n      logger.error('Text summarization error:', error)\n      res.status(500).json({\n        error: 'Summarization failed',\n        message: error instanceof Error ? error.message : 'Unknown error'\n      })\n    }\n  }\n)\n\n// Image Generation\nrouter.post('/image/generate',\n  rateLimitByUser(3, 60), // 3 requests per minute per user\n  [\n    body('prompt').isString().isLength({ min: 1, max: 1000 }),\n    body('size').optional().isIn(['256x256', '512x512', '1024x1024']),\n    body('quality').optional().isIn(['standard', 'hd']),\n    body('style').optional().isIn(['vivid', 'natural'])\n  ],\n  async (req, res) => {\n    try {\n      const errors = validationResult(req)\n      if (!errors.isEmpty()) {\n        return res.status(400).json({ errors: errors.array() })\n      }\n\n      const { prompt, size = '1024x1024', quality = 'standard', style = 'vivid' } = req.body\n      const userId = req.user.id\n\n      logger.info(`Image generation request from user ${userId}`, {\n        prompt: prompt.substring(0, 100),\n        size,\n        quality,\n        style\n      })\n\n      const response = await openai.images.generate({\n        model: 'dall-e-3',\n        prompt,\n        size: size as '1024x1024' | '1792x1024' | '1024x1792',\n        quality: quality as 'standard' | 'hd',\n        style: style as 'vivid' | 'natural',\n        n: 1,\n        user: userId\n      })\n\n      const imageUrl = response.data[0]?.url\n      const revisedPrompt = response.data[0]?.revised_prompt\n\n      if (!imageUrl) {\n        throw new Error('No image URL returned from OpenAI')\n      }\n\n      // Save to database\n      const generation = await prisma.imageGeneration.create({\n        data: {\n          userId,\n          prompt,\n          revisedPrompt,\n          imageUrl,\n          model: 'dall-e-3',\n          parameters: {\n            size,\n            quality,\n            style\n          }\n        }\n      })\n\n      res.json({\n        id: generation.id,\n        imageUrl,\n        prompt,\n        revisedPrompt,\n        size,\n        quality,\n        style,\n        createdAt: generation.createdAt\n      })\n\n    } catch (error) {\n      logger.error('Image generation error:', error)\n      res.status(500).json({\n        error: 'Image generation failed',\n        message: error instanceof Error ? error.message : 'Unknown error'\n      })\n    }\n  }\n)\n\n// Code Analysis\nrouter.post('/code/analyze',\n  rateLimitByUser(5, 60),\n  [\n    body('code').isString().isLength({ min: 1, max: 10000 }),\n    body('language').optional().isString(),\n    body('analysisType').optional().isIn(['security', 'performance', 'quality', 'all'])\n  ],\n  async (req, res) => {\n    try {\n      const errors = validationResult(req)\n      if (!errors.isEmpty()) {\n        return res.status(400).json({ errors: errors.array() })\n      }\n\n      const { code, language = 'javascript', analysisType = 'all' } = req.body\n      const userId = req.user.id\n\n      const analysisPrompts = {\n        security: 'Analyze this code for security vulnerabilities and provide recommendations:',\n        performance: 'Analyze this code for performance issues and suggest optimizations:',\n        quality: 'Review this code for quality, readability, and best practices:',\n        all: 'Provide a comprehensive analysis of this code including security, performance, and quality aspects:'\n      }\n\n      const prompt = `${analysisPrompts[analysisType]}\\n\\nLanguage: ${language}\\n\\nCode:\\n${code}`\n\n      const completion = await openai.chat.completions.create({\n        model: 'gpt-4',\n        messages: [\n          {\n            role: 'system',\n            content: 'You are an expert code reviewer. Provide detailed, actionable feedback on code quality, security, and performance.'\n          },\n          { role: 'user', content: prompt }\n        ],\n        max_tokens: 2000,\n        temperature: 0.3,\n        user: userId\n      })\n\n      const analysis = completion.choices[0]?.message?.content || ''\n      const tokensUsed = completion.usage?.total_tokens || 0\n\n      // Save to database\n      const codeAnalysis = await prisma.codeAnalysis.create({\n        data: {\n          userId,\n          code,\n          language,\n          analysisType,\n          analysis,\n          tokensUsed\n        }\n      })\n\n      res.json({\n        id: codeAnalysis.id,\n        analysis,\n        language,\n        analysisType,\n        tokensUsed,\n        createdAt: codeAnalysis.createdAt\n      })\n\n    } catch (error) {\n      logger.error('Code analysis error:', error)\n      res.status(500).json({\n        error: 'Code analysis failed',\n        message: error instanceof Error ? error.message : 'Unknown error'\n      })\n    }\n  }\n)\n\n// Get user's AI usage history\nrouter.get('/history',\n  async (req, res) => {\n    try {\n      const userId = req.user.id\n      const { type, limit = 20, offset = 0 } = req.query\n\n      const whereClause = { userId }\n      let results: any[] = []\n\n      if (!type || type === 'text') {\n        const textGenerations = await prisma.textGeneration.findMany({\n          where: whereClause,\n          orderBy: { createdAt: 'desc' },\n          take: parseInt(limit as string),\n          skip: parseInt(offset as string),\n          select: {\n            id: true,\n            prompt: true,\n            generatedText: true,\n            model: true,\n            tokensUsed: true,\n            type: true,\n            createdAt: true\n          }\n        })\n        results.push(...textGenerations.map(item => ({ ...item, category: 'text' })))\n      }\n\n      if (!type || type === 'image') {\n        const imageGenerations = await prisma.imageGeneration.findMany({\n          where: whereClause,\n          orderBy: { createdAt: 'desc' },\n          take: parseInt(limit as string),\n          skip: parseInt(offset as string),\n          select: {\n            id: true,\n            prompt: true,\n            imageUrl: true,\n            model: true,\n            createdAt: true\n          }\n        })\n        results.push(...imageGenerations.map(item => ({ ...item, category: 'image' })))\n      }\n\n      if (!type || type === 'code') {\n        const codeAnalyses = await prisma.codeAnalysis.findMany({\n          where: whereClause,\n          orderBy: { createdAt: 'desc' },\n          take: parseInt(limit as string),\n          skip: parseInt(offset as string),\n          select: {\n            id: true,\n            language: true,\n            analysisType: true,\n            analysis: true,\n            tokensUsed: true,\n            createdAt: true\n          }\n        })\n        results.push(...codeAnalyses.map(item => ({ ...item, category: 'code' })))\n      }\n\n      // Sort by creation date\n      results.sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime())\n\n      res.json({\n        history: results.slice(0, parseInt(limit as string)),\n        total: results.length\n      })\n\n    } catch (error) {\n      logger.error('History retrieval error:', error)\n      res.status(500).json({\n        error: 'Failed to retrieve history',\n        message: error instanceof Error ? error.message : 'Unknown error'\n      })\n    }\n  }\n)\n\nexport default router